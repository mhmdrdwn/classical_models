{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26f46c8-2a8a-4a73-9308-d435502bd326",
   "metadata": {},
   "source": [
    "# ChronoNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666faf2-30e3-4ce8-a625-f3c98327fe5a",
   "metadata": {},
   "source": [
    "Here we train the model and record the train and validation accuracy. We used subset of the temple dataset for faster training. we used 500 subjects only for training and validation of the model. The recorded metrics are accuracy, binary cross entropy loss, F1 score, Precision and Recall.\n",
    "\n",
    "- Train Data: 500 subjects\n",
    "\n",
    "- Test Data: 276 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d47023-733f-4137-a16d-a08406cefc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedr/opt/anaconda3/envs/xai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data....\n",
      "Scaling Data....\n",
      "Data Loader....\n",
      "Training Model....\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:37<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6185583529100253 ,Train Accuracy:  0.7934802259887006 ,F1:  0.7612441378949981 ,Precision:  0.9020463762731804 ,Recall:  0.6584632768361582\n",
      "Val loss: 0.6317908183320776 , Val Accuracy:  0.6661016949152543 ,F1:  0.5159229408295657 ,Precision:  0.9376563058235085 ,Recall:  0.355864406779661\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [03:47<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5862326041466928 ,Train Accuracy:  0.7856497175141243 ,F1:  0.7381642512077294 ,Precision:  0.9482269503546099 ,Recall:  0.6042937853107344\n",
      "Val loss: 0.6265238835698083 , Val Accuracy:  0.6772542372881356 ,F1:  0.5373438942611399 ,Precision:  0.9485331960885229 ,Recall:  0.37484745762711863\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [03:43<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5769695649946356 ,Train Accuracy:  0.8252994350282485 ,F1:  0.7993771491598001 ,Precision:  0.9386561023921987 ,Recall:  0.696090395480226\n",
      "Val loss: 0.611729929715524 , Val Accuracy:  0.7238305084745763 ,F1:  0.6365055994289028 ,Precision:  0.9308364870155291 ,Recall:  0.48359322033898305\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [03:44<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5716010270091151 ,Train Accuracy:  0.8470621468926554 ,F1:  0.8297291517278687 ,Precision:  0.935785023126472 ,Recall:  0.7452655367231639\n",
      "Val loss: 0.607604176967175 , Val Accuracy:  0.7368135593220339 ,F1:  0.6608125819134995 ,Precision:  0.9291154791154791 ,Recall:  0.5127457627118645\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [03:53<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5678945554990988 ,Train Accuracy:  0.8633559322033898 ,F1:  0.8515376588300289 ,Precision:  0.9321596559602204 ,Recall:  0.7837514124293785\n",
      "Val loss: 0.6037838544164386 , Val Accuracy:  0.7559661016949153 ,F1:  0.7058150463814311 ,Precision:  0.888385968521757 ,Recall:  0.5854915254237288\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "from load_data import read_data_arrays, data_file_names, standardize_data, data_loader\n",
    "from models import ChronoNet\n",
    "from utils import cal_accuracy, evaluate_model \n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "#device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "print(\"Reading Data....\")\n",
    "sample_size = 500\n",
    "data_files = data_file_names(sample_size)\n",
    "(train_features, val_features, test_features,\n",
    " train_labels, val_labels, test_labels, test_lengths) = read_data_arrays(\n",
    "    data_files)\n",
    "    \n",
    "print(\"Scaling Data....\")\n",
    "train_features, val_features, test_features = standardize_data(\n",
    "    train_features, val_features, test_features)\n",
    "    \n",
    "print(\"Data Loader....\")\n",
    "train_iter = data_loader(train_features, train_labels, DEVICE, BATCH_SIZE)\n",
    "val_iter = data_loader(val_features, val_labels, DEVICE, BATCH_SIZE)\n",
    "test_iter = data_loader(test_features, test_labels, DEVICE, BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "model=ChronoNet(n_chans)\n",
    "model.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, val_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(model, train_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, train_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, train_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, train_iter)[3])\n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(model, val_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, val_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, val_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, val_iter)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4ec1d-fbd4-4d0f-9173-e2ae3534691d",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7220e28-acda-411d-9eec-2c5f22572cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8043478260869565\n",
      "Test Confusion:  [[141   9]\n",
      " [ 45  81]]\n",
      "Test F1:  0.75\n",
      "Test Recall:  0.6428571428571429\n",
      "Test Precision:  0.9\n"
     ]
    }
   ],
   "source": [
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_iter:\n",
    "        yhat = model(x)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "        \n",
    "from collections import Counter\n",
    "\n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619dde7-c736-40dc-a86e-b8dad07c2809",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254afb0b-0902-4330-bc50-14afd53623a5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model....\n",
      "started training\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [07:37<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.657803066204049 ,Train Accuracy:  0.7177966101694915 ,F1:  0.6535244093614305 ,Precision:  0.8462616318758308 ,Recall:  0.5322937853107345\n",
      "Val loss: 0.6684723841209038 , Val Accuracy:  0.5790508474576271 ,F1:  0.31679137323943657 ,Precision:  0.8403385872737886 ,Recall:  0.1951864406779661\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [09:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     31\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m evaluate_model(model, loss_func, test_iter)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss_sum \u001b[38;5;241m/\u001b[39m (t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Train Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     33\u001b[0m     cal_accuracy(model, train_iter)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,F1: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     34\u001b[0m     cal_accuracy(model, train_iter)[\u001b[38;5;241m4\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Precision: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m---> 35\u001b[0m     \u001b[43mcal_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Recall: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     36\u001b[0m     cal_accuracy(model, train_iter)[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, Val Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     38\u001b[0m     cal_accuracy(model, val_iter)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,F1: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     39\u001b[0m     cal_accuracy(model, val_iter)[\u001b[38;5;241m4\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Precision: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     40\u001b[0m     cal_accuracy(model, val_iter)[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,Recall: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     41\u001b[0m     cal_accuracy(model, val_iter)[\u001b[38;5;241m3\u001b[39m])\n",
      "File \u001b[0;32m~/projects/classical_models/utils.py:41\u001b[0m, in \u001b[0;36mcal_accuracy\u001b[0;34m(model, data_iter)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m data_iter:\n\u001b[0;32m---> 41\u001b[0m         yhat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m         yhat \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m yhat]\n\u001b[1;32m     43\u001b[0m         ytrue\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mlist\u001b[39m(y\u001b[38;5;241m.\u001b[39mnumpy()))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/classical_models/models.py:81\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_units)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m     80\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_units)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[0;32m---> 81\u001b[0m lstm_out, (hn, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(hn[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     83\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(out)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models import LSTM\n",
    "\n",
    "learning_rate = 5e-3\n",
    "\n",
    "model = LSTM(input_size=500, num_channels=19, hidden_units=128)\n",
    "\n",
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "model.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "print(\"started training\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, test_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(model, train_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, train_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, train_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, train_iter)[3])\n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(model, val_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, val_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, val_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, val_iter)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82189487-7315-4a8c-b73f-f60d7c24c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6159420289855072\n",
      "Test Confusion:  [[149   1]\n",
      " [105  21]]\n",
      "Test F1:  0.28378378378378377\n",
      "Test Recall:  0.16666666666666666\n",
      "Test Precision:  0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_iter:\n",
    "        yhat = model(x)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "\n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c418d8-e644-4ab4-ad65-be78bb384eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
