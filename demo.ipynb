{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7bb62f",
   "metadata": {},
   "source": [
    "## Read Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9262a0f-0256-44a9-bd89-0787fe3589d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1372\n"
     ]
    }
   ],
   "source": [
    "!ls -l tuh/train/normal/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc8af113-a47e-4870-bd9c-f02a01a68006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1347\n"
     ]
    }
   ],
   "source": [
    "!ls -l tuh/train/abnormal/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33fba98-1b2f-4d3e-95e1-9b86d6500162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     127\n"
     ]
    }
   ],
   "source": [
    "!ls -l tuh/eval/abnormal/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44fb6410-4c74-4a36-9c61-2d3e4a8f9127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     151\n"
     ]
    }
   ],
   "source": [
    "!ls -l tuh/eval/normal/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74354c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xai\n"
     ]
    }
   ],
   "source": [
    "!echo $CONDA_DEFAULT_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4cdb3a-c467-4980-83f2-1ef23a00768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 19, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read sample data file\n",
    "import numpy as np\n",
    "\n",
    "test_file = np.load(\"tuh/train/normal/10005_0_65_F_1133.npy\")\n",
    "test_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77b8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "import os\n",
    "import mne\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f56cede-65fd-4fce-8052-d76c18db0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_abnormal_files = glob.glob('./tuh/eval/abnormal/*.npy')\n",
    "test_normal_files = glob.glob('./tuh/eval/normal/*.npy')\n",
    "train_normal_files = glob.glob('./tuh/train/normal/*.npy')\n",
    "train_abnormal_files = glob.glob('./tuh/train/abnormal/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b304eb8-93a9-4fc9-9b7e-d1c050e0fd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1346, 150)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_abnormal_files), len(test_normal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0999cde3-1b1a-41fd-92c6-d1d1aaa5c7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#val_normal_files = random.sample(train_normal_files, 100)\n",
    "#val_abnormal_files = random.sample(train_abnormal_files, 100)\n",
    "train_normal_files = random.sample(train_normal_files, 300)\n",
    "train_abnormal_files = random.sample(train_abnormal_files, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dafdac53-9353-453d-a318-1a5d9611c0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_abnormal_files), len(train_normal_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c846b936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "train_normal_features=[np.load(f) for f in train_normal_files]\n",
    "train_abnormal_features=[np.load(f) for f in train_abnormal_files]\n",
    "test_normal_features=[np.load(f) for f in test_normal_files]\n",
    "test_abnormal_features=[np.load(f) for f in test_abnormal_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6555a634-ab12-4a27-92c3-adc945639b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 19, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normal_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d20a0a9-2fdd-4f40-b4fe-3646ac7106ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 19, 500)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_abnormal_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05d9173e-c1e1-4722-a648-c71f23845e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normal_labels=[len(i)*[0] for i in train_normal_features]\n",
    "train_abnormal_labels=[len(i)*[1] for i in train_abnormal_features]\n",
    "\n",
    "test_normal_labels=[len(i)*[0] for i in test_normal_features]\n",
    "test_abnormal_labels=[len(i)*[1] for i in test_abnormal_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e929e2b-7457-4e12-8c0b-eb7d837649b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_normal_features + train_abnormal_features\n",
    "train_labels = train_normal_labels + train_abnormal_labels\n",
    "\n",
    "test_features = test_normal_features + test_abnormal_features\n",
    "test_labels = test_normal_labels + test_abnormal_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "625b5c0d-6a06-418e-8791-1714ebfbaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_normal_features\n",
    "del train_abnormal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89dd9e61-083e-4d89-8ccc-a55984dba6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.vstack(train_features)\n",
    "train_labels = np.hstack(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee677aef-ca42-4daf-9fac-b3d0c72b6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.vstack(test_features)\n",
    "test_labels = np.hstack(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "249ab5bc-608a-464e-86f1-2f88bc578fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "gkf=GroupKFold()\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#https://stackoverflow.com/questions/50125844/how-to-standard-scale-a-3d-matrix\n",
    "class StandardScaler3D(BaseEstimator,TransformerMixin):\n",
    "    #batch, sequence, channels\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        self.scaler.fit(X.reshape(-1, X.shape[2]))\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "        return self.scaler.transform(X.reshape( -1,X.shape[2])).reshape(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3afd2c7a-0469-4c57-8496-41ab5c14bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler3D()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0acc9a-5667-42c3-a975-d65863b18504",
   "metadata": {},
   "source": [
    "## ChronoNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2047317b-daaf-4cad-bb2a-807e54c0989f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedr/opt/anaconda3/envs/xai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self,inplace):\n",
    "    super().__init__()\n",
    "    self.conv1=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=2,stride=2,padding=0)\n",
    "    self.conv2=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=4,stride=2,padding=1)\n",
    "    self.conv3=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=8,stride=2,padding=3)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x1=self.relu(self.conv1(x))\n",
    "    x2=self.relu(self.conv2(x))\n",
    "    x3=self.relu(self.conv3(x))\n",
    "    x=torch.cat([x1,x3,x3],dim=1)\n",
    "    return x\n",
    "\n",
    "class ChronoNet(nn.Module):\n",
    "  def __init__(self,channel):\n",
    "    super().__init__()\n",
    "    self.block1=Block(channel)\n",
    "    self.block2=Block(96)\n",
    "    self.block3=Block(96)\n",
    "    self.gru1=nn.GRU(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru2=nn.GRU(input_size=32,hidden_size=32,batch_first=True)\n",
    "    self.gru3=nn.GRU(input_size=64,hidden_size=32,batch_first=True)\n",
    "    self.gru4=nn.GRU(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru_linear=nn.Linear(62,1)\n",
    "    self.flatten=nn.Flatten()\n",
    "    self.fc1=nn.Linear(32,1)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = x.squeeze()\n",
    "    x=self.block1(x)\n",
    "    x=self.block2(x)\n",
    "    x=self.block3(x)\n",
    "    x=x.permute(0,2,1)\n",
    "    gru_out1,_=self.gru1(x)\n",
    "    gru_out2,_=self.gru2(gru_out1)\n",
    "    gru_out=torch.cat([gru_out1,gru_out2],dim=2)\n",
    "    gru_out3,_=self.gru3(gru_out)\n",
    "    gru_out=torch.cat([gru_out1,gru_out2,gru_out3],dim=2)\n",
    "    linear_out=self.relu(self.gru_linear(gru_out.permute(0,2,1)))\n",
    "    gru_out4,_=self.gru4(linear_out.permute(0,2,1))\n",
    "    x=self.flatten(gru_out4)\n",
    "    x=self.fc1(x)\n",
    "    out = torch.sigmoid(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a20d5089-2d78-4c39-90d7-1e5de94b9ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "train_features = torch.Tensor(train_features).float().to(device)\n",
    "train_labels = torch.Tensor(train_labels).float().to(device)\n",
    "batch_size = 128\n",
    "train_data = torch.utils.data.TensorDataset(train_features, train_labels)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "\n",
    "test_features = torch.Tensor(test_features).float().to(device)\n",
    "test_labels = torch.Tensor(test_labels).float().to(device)\n",
    "\n",
    "test_data = torch.utils.data.TensorDataset(test_features, val_labels)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "823dd9f3-83ed-4ba1-bd94-a982c02fe8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loss_func, data_iter):\n",
    "    model.eval()\n",
    "    loss_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_iter:\n",
    "            y_pred = model(x)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = loss_func(y_pred,y)\n",
    "            loss_sum += loss.item()\n",
    "            n += 1\n",
    "        return loss_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a15a9f26-f38f-47d6-ae73-b44ee6ba0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def print_accuracy(model, labels, features):\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(features)\n",
    "\n",
    "    yhat = [0 if i<0.5 else 1 for i in y_hat]\n",
    "    ytrue = labels.numpy()\n",
    "    ypreds = yhat\n",
    "\n",
    "    print(\"Accuracy: \", accuracy_score(ytrue, ypreds))\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion_matrix(ytrue, ypreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e569ea71-7b1e-4edd-8f1a-7a3bd7d7b5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [03:57<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.6344686868173551\n",
      "Accuracy:  0.7718644067796611\n",
      "Confusion Matrix: \n",
      "[[29822  5578]\n",
      " [10574 24826]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6312071293008094\n",
      "Accuracy:  0.7574613117170228\n",
      "Confusion Matrix: \n",
      "[[14868  2832]\n",
      " [ 5067  9801]]\n",
      "None\n",
      "epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [04:29<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.6003486813190612\n",
      "Accuracy:  0.7966949152542373\n",
      "Confusion Matrix: \n",
      "[[31722  3678]\n",
      " [10716 24684]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6185130250220205\n",
      "Accuracy:  0.7772660280029476\n",
      "Confusion Matrix: \n",
      "[[15631  2069]\n",
      " [ 5185  9683]]\n",
      "None\n",
      "epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [04:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5895372779791106\n",
      "Accuracy:  0.819858757062147\n",
      "Confusion Matrix: \n",
      "[[31959  3441]\n",
      " [ 9313 26087]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6137760583092184\n",
      "Accuracy:  0.7918816015720953\n",
      "Confusion Matrix: \n",
      "[[15529  2171]\n",
      " [ 4607 10261]]\n",
      "None\n",
      "epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [07:29<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5847568748660036\n",
      "Accuracy:  0.8333050847457627\n",
      "Confusion Matrix: \n",
      "[[31848  3552]\n",
      " [ 8250 27150]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6171275985007193\n",
      "Accuracy:  0.7881970031933186\n",
      "Confusion Matrix: \n",
      "[[15160  2540]\n",
      " [ 4358 10510]]\n",
      "None\n",
      "epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [08:39<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5778848887135406\n",
      "Accuracy:  0.8202824858757062\n",
      "Confusion Matrix: \n",
      "[[33975  1425]\n",
      " [11299 24101]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6080520136683595\n",
      "Accuracy:  0.7884733480717269\n",
      "Confusion Matrix: \n",
      "[[16478  1222]\n",
      " [ 5667  9201]]\n",
      "None\n",
      "epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [04:15<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5735900268657973\n",
      "Accuracy:  0.8555790960451978\n",
      "Confusion Matrix: \n",
      "[[31711  3689]\n",
      " [ 6536 28864]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.617899690656101\n",
      "Accuracy:  0.7958118398427905\n",
      "Confusion Matrix: \n",
      "[[14865  2835]\n",
      " [ 3815 11053]]\n",
      "None\n",
      "epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [04:04<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5687553438253782\n",
      "Accuracy:  0.8505367231638418\n",
      "Confusion Matrix: \n",
      "[[29701  5699]\n",
      " [ 4883 30517]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6305400200918609\n",
      "Accuracy:  0.7806128715303365\n",
      "Confusion Matrix: \n",
      "[[13681  4019]\n",
      " [ 3126 11742]]\n",
      "None\n",
      "epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [03:57<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5664093874206612\n",
      "Accuracy:  0.8675423728813559\n",
      "Confusion Matrix: \n",
      "[[32957  2443]\n",
      " [ 6935 28465]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.612890966499553\n",
      "Accuracy:  0.7984831736674036\n",
      "Confusion Matrix: \n",
      "[[15343  2357]\n",
      " [ 4206 10662]]\n",
      "None\n",
      "epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [04:07<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5646616778864327\n",
      "Accuracy:  0.8697033898305084\n",
      "Confusion Matrix: \n",
      "[[31489  3911]\n",
      " [ 5314 30086]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6220441383474014\n",
      "Accuracy:  0.7937239007614837\n",
      "Confusion Matrix: \n",
      "[[14361  3339]\n",
      " [ 3379 11489]]\n",
      "None\n",
      "epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 554/554 [03:55<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "#####\n",
      "Train loss: 0.5657099489700923\n",
      "Accuracy:  0.8672457627118644\n",
      "Confusion Matrix: \n",
      "[[33598  1802]\n",
      " [ 7597 27803]]\n",
      "None\n",
      "Val\n",
      "#####\n",
      "Val loss: 0.6082649340816573\n",
      "Accuracy:  0.8011545074920167\n",
      "Confusion Matrix: \n",
      "[[15823  1877]\n",
      " [ 4599 10269]]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_chans = 19\n",
    "model=ChronoNet(n_chans)\n",
    "model.to(device)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(\"epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, val_iter)\n",
    "    print(\"Train\")\n",
    "    print(\"#####\")\n",
    "    print(\"loss:\", loss_sum / (t+1))\n",
    "    print(print_accuracy(model, train_labels, train_features))\n",
    "    print(\"Val\")\n",
    "    print(\"#####\")\n",
    "    print(\"loss:\", val_loss)\n",
    "    print(print_accuracy(model, val_labels, val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96d47023-733f-4137-a16d-a08406cefc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8011545074920167\n",
      "Confusion Matrix: \n",
      "[[15823  1877]\n",
      " [ 4599 10269]]\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(model, val_labels, val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b530c-b6c4-4bff-a7ef-504efe741893",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78319cc4-8e61-459a-bc71-3d2f8a16a93f",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727cc7e-c7f7-434b-b4d5-ff61e50fa9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "    \n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, output_size, input_size, hidden_size, num_layers, num_channels=19):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_channels = num_channels\n",
    "        self.LSTMs = []\n",
    "        self.vars_h0 = []\n",
    "        self.vars_c0 = []\n",
    "        for _ in range(self.num_channels):\n",
    "            h0 = Variable(torch.zeros(self.num_layers*2, 32, \n",
    "                                      self.hidden_size))\n",
    "            c0 = Variable(torch.zeros(self.num_layers*2, 32, \n",
    "                                      self.hidden_size))\n",
    "            self.vars_h0.append(h0)\n",
    "            self.vars_c0.append(c0)\n",
    "            \n",
    "            lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True, \n",
    "                            bidirectional=True)\n",
    "            self.LSTMs.append(lstm)\n",
    "        self.linear = nn.Linear(hidden_size*2, 8)\n",
    "        self.out_linear = nn.Linear(8*num_channels, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ch_out = [] \n",
    "        for ch_idx in range(self.num_channels):\n",
    "            h0 = self.vars_h0[ch_idx]\n",
    "            c0 = self.vars_c0[ch_idx]    \n",
    "            x_ch = x[:, ch_idx, :]\n",
    "            x_ch = x_ch.unsqueeze(1)\n",
    "            lstm_out, (hn, cn) = self.LSTMs[ch_idx](x_ch, (h0, c0))\n",
    "            out = hn.view(-1, self.hidden_size*2)\n",
    "            out = self.linear(out)\n",
    "            ch_out.append(out)\n",
    "        ch_out = torch.cat(ch_out, dim=1)\n",
    "        out = self.out_linear(ch_out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18513ff-62a8-4457-a5e8-a42f9e330a3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_chans = 19\n",
    "model = LSTM(output_size=1, input_size=500, hidden_size=32, num_layers=1, num_channels=n_chans)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(\"epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        if x.size(0) != 32:\n",
    "            break\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        y = y.float()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, val_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1))\n",
    "    print(\"Val loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661eea0-f245-46bf-9fff-b08c1156f9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_accuracy(model, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e943b2d-2323-48fd-aff1-497d444d64e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
