{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26f46c8-2a8a-4a73-9308-d435502bd326",
   "metadata": {},
   "source": [
    "# ChronoNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666faf2-30e3-4ce8-a625-f3c98327fe5a",
   "metadata": {},
   "source": [
    "Here we train the model and record the train and validation accuracy. We used subset of the temple dataset for faster training. we used 500 subjects only for training and validation of the model. The recorded metrics are accuracy, binary cross entropy loss, F1 score, Precision and Recall.\n",
    "\n",
    "- Train Data: 500 subjects\n",
    "\n",
    "- Test Data: 276 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99194e02-6f9f-4609-8e16-600c35eaddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1371\n"
     ]
    }
   ],
   "source": [
    "!ls tuh/train/normal/* | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d47023-733f-4137-a16d-a08406cefc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedr/opt/anaconda3/envs/xai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data....\n",
      "Scaling Data....\n",
      "Data Loader....\n",
      "Training Model....\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:34<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6135080639337529 ,Train Accuracy:  0.7996045197740113 ,F1:  0.7803633571525878 ,Precision:  0.8632490341671918 ,Recall:  0.712\n",
      "Val loss: 0.6022120368429077 , Val Accuracy:  0.7723050847457628 ,F1:  0.741564387672656 ,Precision:  0.8573080686771639 ,Recall:  0.6533559322033898\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:21<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5856635680777489 ,Train Accuracy:  0.8226892655367232 ,F1:  0.7964404317144043 ,Precision:  0.934831597539436 ,Recall:  0.6937401129943502\n",
      "Val loss: 0.5953799966093781 , Val Accuracy:  0.7829830508474577 ,F1:  0.7506232471174821 ,Precision:  0.8821644387474822 ,Recall:  0.6532203389830509\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:45<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5753913293511881 ,Train Accuracy:  0.8453446327683616 ,F1:  0.8308555469049296 ,Precision:  0.9167416618942431 ,Recall:  0.7596836158192091\n",
      "Val loss: 0.5960082494335257 , Val Accuracy:  0.792 ,F1:  0.7715221924337206 ,Precision:  0.8557739963654386 ,Recall:  0.7023728813559322\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:30<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.570163000353499 ,Train Accuracy:  0.8605762711864406 ,F1:  0.8510484192228297 ,Precision:  0.9134727513021845 ,Recall:  0.7966101694915254\n",
      "Val loss: 0.595359214972624 , Val Accuracy:  0.7965084745762712 ,F1:  0.7804717498628635 ,Precision:  0.8472409686383485 ,Recall:  0.723457627118644\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:15<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.565777277498576 ,Train Accuracy:  0.8552542372881355 ,F1:  0.8381267691063485 ,Precision:  0.9506105601100728 ,Recall:  0.7494463276836159\n",
      "Val loss: 0.5963385198023412 , Val Accuracy:  0.7821016949152543 ,F1:  0.7513346228239846 ,Precision:  0.8748648648648648 ,Recall:  0.6583728813559322\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "from load_data import read_data_arrays, data_file_names, standardize_data, data_loader\n",
    "from models import ChronoNet\n",
    "from utils import cal_accuracy, evaluate_model \n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "#device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "print(\"Reading Data....\")\n",
    "sample_size = 500\n",
    "data_files = data_file_names(sample_size)\n",
    "(train_features, val_features, test_features,\n",
    " train_labels, val_labels, test_labels, test_lengths) = read_data_arrays(\n",
    "    data_files)\n",
    "    \n",
    "print(\"Scaling Data....\")\n",
    "train_features, val_features, test_features = standardize_data(\n",
    "    train_features, val_features, test_features)\n",
    "    \n",
    "print(\"Data Loader....\")\n",
    "train_iter = data_loader(train_features, train_labels, DEVICE, BATCH_SIZE)\n",
    "val_iter = data_loader(val_features, val_labels, DEVICE, BATCH_SIZE)\n",
    "test_iter = data_loader(test_features, test_labels, DEVICE, BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "model=ChronoNet(n_chans)\n",
    "model.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, val_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(model, train_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, train_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, train_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, train_iter)[3])\n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(model, val_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, val_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, val_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, val_iter)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4ec1d-fbd4-4d0f-9173-e2ae3534691d",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7220e28-acda-411d-9eec-2c5f22572cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8188405797101449\n",
      "Test Confusion:  [[141   9]\n",
      " [ 41  85]]\n",
      "Test F1:  0.7727272727272727\n",
      "Test Recall:  0.6746031746031746\n",
      "Test Precision:  0.9042553191489362\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_iter:\n",
    "        yhat = model(x)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "        \n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619dde7-c736-40dc-a86e-b8dad07c2809",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254afb0b-0902-4330-bc50-14afd53623a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model....\n",
      "started training\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [08:51<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.661770528279288 ,Train Accuracy:  0.7018870056497175 ,F1:  0.624489389259739 ,Precision:  0.843477257872275 ,Recall:  0.49577401129943505\n",
      "Val loss: 0.67322963032068 , Val Accuracy:  0.5675593220338983 ,F1:  0.2789803877239586 ,Precision:  0.8386000679578661 ,Recall:  0.16732203389830508\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [36:10<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6248360861071273 ,Train Accuracy:  0.7378757062146892 ,F1:  0.6679738936279842 ,Precision:  0.9108829729096729 ,Recall:  0.5273446327683616\n",
      "Val loss: 0.6709002801016265 , Val Accuracy:  0.5743050847457627 ,F1:  0.2901074053137365 ,Precision:  0.8727891156462585 ,Recall:  0.17396610169491525\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [13:54<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6036012842820558 ,Train Accuracy:  0.7931073446327683 ,F1:  0.7555798803929944 ,Precision:  0.9229991520448764 ,Recall:  0.6395706214689265\n",
      "Val loss: 0.6608413919514301 , Val Accuracy:  0.602 ,F1:  0.3752461022721226 ,Precision:  0.8721246599060104 ,Recall:  0.2390508474576271\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [13:37<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5900325086075446 ,Train Accuracy:  0.8101694915254237 ,F1:  0.777824798984342 ,Precision:  0.937575718931327 ,Recall:  0.6645875706214689\n",
      "Val loss: 0.6607672583823111 , Val Accuracy:  0.604 ,F1:  0.37907940895078135 ,Precision:  0.8774606299212598 ,Recall:  0.2417627118644068\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [17:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5812325871231928 ,Train Accuracy:  0.833683615819209 ,F1:  0.8115485564304462 ,Precision:  0.9361394181066313 ,Recall:  0.716225988700565\n",
      "Val loss: 0.6539293941329507 , Val Accuracy:  0.6249830508474576 ,F1:  0.44049967126890205 ,Precision:  0.8670117459685447 ,Recall:  0.2952542372881356\n"
     ]
    }
   ],
   "source": [
    "from models import LSTM\n",
    "\n",
    "learning_rate = 5e-3\n",
    "\n",
    "model = LSTM(input_size=500, num_channels=19, hidden_units=128)\n",
    "\n",
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "model.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "print(\"started training\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, test_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(model, train_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, train_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, train_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, train_iter)[3])\n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(model, val_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, val_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, val_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, val_iter)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82189487-7315-4a8c-b73f-f60d7c24c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6485507246376812\n",
      "Test Confusion:  [[149   1]\n",
      " [ 96  30]]\n",
      "Test F1:  0.38216560509554137\n",
      "Test Recall:  0.23809523809523808\n",
      "Test Precision:  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_iter:\n",
    "        yhat = model(x)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "\n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ba1b7-5469-4d4d-b942-2e97c64fde87",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "af0f36fc-045e-4a3e-9834-aa6a1836ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self,inplace):\n",
    "    super().__init__()\n",
    "    self.conv1=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=2,stride=2,padding=0)\n",
    "    self.conv2=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=4,stride=2,padding=1)\n",
    "    self.conv3=nn.Conv1d(in_channels=inplace,out_channels=32,kernel_size=8,stride=2,padding=3)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x1=self.relu(self.conv1(x))\n",
    "    x2=self.relu(self.conv2(x))\n",
    "    x3=self.relu(self.conv3(x))\n",
    "    x=torch.cat([x1,x3,x3],dim=1)\n",
    "    return x\n",
    "\n",
    "class ChronoNet(nn.Module):\n",
    "  def __init__(self,channel):\n",
    "    super().__init__()\n",
    "    self.block1=Block(channel)\n",
    "    self.block2=Block(96)\n",
    "    self.block3=Block(96)\n",
    "    self.gru1=nn.LSTM(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru2=nn.LSTM(input_size=32,hidden_size=32,batch_first=True)\n",
    "    self.gru3=nn.LSTM(input_size=64,hidden_size=32,batch_first=True)\n",
    "    self.gru4=nn.LSTM(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru_linear=nn.Linear(62,1)\n",
    "    self.flatten=nn.Flatten()\n",
    "    self.fc1=nn.Linear(32,1)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = x.squeeze()\n",
    "    #print(x.shape)\n",
    "    x=self.block1(x)\n",
    "    #print(x.shape)\n",
    "    x=self.block2(x)\n",
    "    #print(x.shape)\n",
    "    x=self.block3(x)\n",
    "    #print(x.shape)\n",
    "    x=x.permute(0,2,1)\n",
    "    #print(x.shape)\n",
    "    gru_out1,_=self.gru1(x)\n",
    "    #print(gru_out1.shape)\n",
    "    gru_out2,_=self.gru2(gru_out1)\n",
    "    #print(gru_out2.shape)\n",
    "    gru_out=torch.cat([gru_out1, gru_out2],dim=2)\n",
    "    #print(gru_out.shape)\n",
    "    gru_out3,_=self.gru3(gru_out)\n",
    "    #print(gru_out3.shape)\n",
    "    gru_out=torch.cat([gru_out1, gru_out2, gru_out3],dim=2)\n",
    "    #print(\"aaa\", gru_out.shape)\n",
    "    linear_out=self.relu(self.gru_linear(gru_out.permute(0,2,1)))\n",
    "    #print(linear_out.shape)\n",
    "    gru_out4,_=self.gru4(linear_out.permute(0,2,1))\n",
    "    #print(gru_out4.shape)\n",
    "    x=self.flatten(gru_out4)\n",
    "    #print(x.shape)\n",
    "    x=self.fc1(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, num_channels, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 2\n",
    "        self.input_size = input_size\n",
    "        self.inputsize_channels = num_channels * input_size\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_channels,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "        self.enc = nn.Linear(in_features=self.inputsize_channels, out_features=19*num_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, x.shape[1]*x.shape[2])\n",
    "        #print(x.shape)\n",
    "        x = self.enc(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(batch_size, int(x.shape[-1]/self.num_channels), self.num_channels)\n",
    "        #print(x.shape)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        lstm_out, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        #print(hn.shape)\n",
    "        out = self.linear(hn[0]).flatten()\n",
    "        #print(lstm_out.shape)\n",
    "        #print(lstm_out.shape)\n",
    "        #lstm_out = lstm_out.view(batch_size,int(lstm_out.shape[-1]/19), 19)\n",
    "        #out = torch.sigmoid(out)\n",
    "        return lstm_out\n",
    "\n",
    "    \n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        #self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        #if bias:\n",
    "        #    self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        #else:\n",
    "        #    self.register_parameter('bias', None)\n",
    "        #self.reset_parameters()\n",
    "        \n",
    "        self.LSTM = ChronoNet(19)#LSTM(input_size=500, num_channels=19, hidden_units=128)\n",
    "        \n",
    "    #def reset_parameters(self):\n",
    "    #    stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "    #    self.weight.data.uniform_(-stdv, stdv)\n",
    "    #    if self.bias is not None:\n",
    "    #        self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.matmul(adj, input)\n",
    "        #print(\"INPUT\", input.shape)\n",
    "        output = self.LSTM(support)\n",
    "        #print(adj.shape, support.shape)\n",
    "        #support = torch.mm(input, self.weight)\n",
    "        \n",
    "        #if self.bias is not None:\n",
    "        #    return output + self.bias\n",
    "        #else:\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "    \n",
    "    \n",
    "    \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nclass)\n",
    "        #self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.fc1=nn.Linear(2432,1)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        #x = F.dropout(x, self.dropout, training=self.training)\n",
    "        #x = self.gc2(x, adj)\n",
    "        #print(x.shape)\n",
    "        #out = x.view(x.shape[0], x.shape[1]*x.shape[2])\n",
    "        #out = self.fc1(out)\n",
    "        #out = torch.sigmoid(out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f2a3f968-7258-4486-a596-7322caf5cd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 19, 500])\n",
      "torch.Size([3, 96, 250])\n",
      "torch.Size([3, 96, 125])\n",
      "torch.Size([3, 96, 62])\n",
      "torch.Size([3, 62, 96])\n",
      "torch.Size([3, 62, 32])\n",
      "torch.Size([3, 62, 32])\n",
      "torch.Size([3, 62, 64])\n",
      "torch.Size([3, 62, 32])\n",
      "aaa torch.Size([3, 62, 96])\n",
      "torch.Size([3, 96, 1])\n",
      "torch.Size([3, 1, 32])\n",
      "torch.Size([3, 32])\n",
      "##########\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0679, -0.0494, -0.0534,  ...,  0.0110,  0.0654,  0.0448],\n",
       "         [ 0.1034, -0.0800, -0.0946,  ...,  0.0159,  0.0880,  0.0647],\n",
       "         [ 0.1202, -0.0915, -0.1146,  ...,  0.0091,  0.0978,  0.0736],\n",
       "         ...,\n",
       "         [ 0.1205, -0.1052, -0.1246,  ...,  0.0066,  0.0946,  0.0791],\n",
       "         [ 0.1166, -0.1080, -0.1335,  ...,  0.0127,  0.0814,  0.0744],\n",
       "         [ 0.1138, -0.1105, -0.1390,  ...,  0.0084,  0.0852,  0.0808]],\n",
       "\n",
       "        [[ 0.0693, -0.0498, -0.0608,  ...,  0.0096,  0.0643,  0.0452],\n",
       "         [ 0.1027, -0.0793, -0.0968,  ...,  0.0076,  0.0923,  0.0707],\n",
       "         [ 0.1160, -0.0911, -0.1170,  ...,  0.0051,  0.1012,  0.0773],\n",
       "         ...,\n",
       "         [ 0.1190, -0.1097, -0.1316,  ...,  0.0085,  0.0847,  0.0769],\n",
       "         [ 0.1159, -0.1112, -0.1352,  ...,  0.0168,  0.0696,  0.0688],\n",
       "         [ 0.1118, -0.1129, -0.1383,  ...,  0.0069,  0.0786,  0.0773]],\n",
       "\n",
       "        [[ 0.0709, -0.0497, -0.0579,  ...,  0.0101,  0.0649,  0.0422],\n",
       "         [ 0.1102, -0.0792, -0.0971,  ...,  0.0077,  0.0912,  0.0671],\n",
       "         [ 0.1238, -0.0884, -0.1135,  ...,  0.0035,  0.1034,  0.0718],\n",
       "         ...,\n",
       "         [ 0.1169, -0.1089, -0.1322,  ...,  0.0113,  0.0925,  0.0793],\n",
       "         [ 0.1129, -0.1095, -0.1360,  ...,  0.0119,  0.0835,  0.0746],\n",
       "         [ 0.1148, -0.1089, -0.1370,  ...,  0.0075,  0.0850,  0.0795]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_net = ChronoNet(19)\n",
    "ls = LSTM(500, 19, 32)\n",
    "ch_net(features)\n",
    "print(\"##########\")\n",
    "ls(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88385ea-7be3-4adb-8dfa-aeb32d02e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7d7fa06e-4769-45a6-be07-9c44c845a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adj.shape, features.shape\n",
    "features = torch.rand(3, 19, 500)\n",
    "adj = torch.rand(3, 19, 19)\n",
    "aa = torch.matmul(adj, features)\n",
    "#aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d64e02fd-4c35-417a-8d52-019b003dd343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88500, 19, 500)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ba834795-c35e-468d-8a04-d4a7ca0169af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 88500/88500 [42:04<00:00, 35.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mstats\n",
    "from tqdm import tqdm\n",
    "\"\"\"\n",
    "adj = []\n",
    "for feat in train_features:\n",
    "    for ch in feat:\n",
    "        pcorr = mstats.pearsonr([1, 2, 3, 4, 5], [10, 9, 2.5, 6, 4])[0]\n",
    "        adj.append(pcorr)\n",
    "\"\"\" \n",
    "\n",
    "adj=[]\n",
    "for f_t in tqdm(train_features):\n",
    "    matrix = []\n",
    "    for i in range(19):\n",
    "        row = []\n",
    "        for j in range(19):\n",
    "            res = mstats.pearsonr(f_t[i, :], f_t[j, :])\n",
    "            row.append(res[0])\n",
    "        matrix.append(row)\n",
    "        #matrix = np.array(matrix)\n",
    "    adj.append(matrix)\n",
    "adj=np.array(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0db6ed41-0b10-4df3-ba2b-409681ec3c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 29500/29500 [14:04<00:00, 34.94it/s]\n"
     ]
    }
   ],
   "source": [
    "val_adj = []\n",
    "for f_t in tqdm(val_features):\n",
    "    matrix = []\n",
    "    for i in range(19):\n",
    "        row = []\n",
    "        for j in range(19):\n",
    "            res = mstats.pearsonr(f_t[i, :], f_t[j, :])\n",
    "            row.append(res[0])\n",
    "        matrix.append(row)\n",
    "        #matrix = np.array(matrix)\n",
    "    val_adj.append(matrix)\n",
    "val_adj = np.array(val_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6b7a8860-8e7c-4156-a0b3-23782aa52683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 32568/32568 [15:39<00:00, 34.67it/s]\n"
     ]
    }
   ],
   "source": [
    "test_adj = []\n",
    "for f_t in tqdm(test_features):\n",
    "    matrix = []\n",
    "    for i in range(19):\n",
    "        row = []\n",
    "        for j in range(19):\n",
    "            res = mstats.pearsonr(f_t[i, :], f_t[j, :])\n",
    "            row.append(res[0])\n",
    "        matrix.append(row)\n",
    "        #matrix = np.array(matrix)\n",
    "    test_adj.append(matrix)\n",
    "test_adj = np.array(test_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c9be2e9d-2c79-49e7-b94d-d4a66a9c82a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([88500, 19, 19]),\n",
       " torch.Size([88500, 19, 500]),\n",
       " torch.Size([88500]),\n",
       " (29500, 19, 500),\n",
       " torch.Size([29500, 19, 19]),\n",
       " (29500,))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape, train_features.shape, train_labels.shape, val_features.shape, val_adj.shape , val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8d1eafc5-74d7-4508-b460-422a5f9b4a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 19, 128])\n",
      "torch.Size([3, 19, 19]) torch.Size([3, 19, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 19, 128])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "output = model(features, adj)\n",
    "output.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "24384641-6bac-47cc-84dd-1c5c435dcc55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 19, 500])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.rand(3, 19, 500)\n",
    "adj = torch.rand(3, 19, 19)\n",
    "aa = torch.matmul(adj, features)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "beaecbf5-b0c5-47b4-8c44-69bf19fc64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(nfeat=features.shape[1], nhid=4, nclass=2, dropout=0.5)\n",
    "out = gcn(features, adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "dd545f6c-901a-420b-bb8a-2c25bee229fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_features = torch.Tensor(train_features).float().to(device)\n",
    "#train_labels = torch.Tensor(train_labels).float().to(device)\n",
    "adj = torch.Tensor(adj).float().to(device)\n",
    "data = torch.utils.data.TensorDataset(train_features, adj, train_labels)\n",
    "data_iter = torch.utils.data.DataLoader(data, 128, shuffle=True)\n",
    "\n",
    "val_adj = torch.Tensor(val_adj).float().to(device)\n",
    "val_labels = torch.Tensor(val_labels).float().to(device)\n",
    "val_features = torch.Tensor(val_features).float().to(device)\n",
    "data = torch.utils.data.TensorDataset(val_features, val_adj, val_labels)\n",
    "val_data_iter = torch.utils.data.DataLoader(data, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3e3c8d89-ccea-4071-abf2-b866d959d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_adj = torch.Tensor(test_adj).float().to(device)\n",
    "test_labels = torch.Tensor(test_labels).float().to(device)\n",
    "test_features = torch.Tensor(test_features).float().to(device)\n",
    "data = torch.utils.data.TensorDataset(test_features, test_adj, test_labels)\n",
    "test_data_iter = torch.utils.data.DataLoader(data, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5fa90b13-a423-45ab-b629-797048837177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(model, data_iter):\n",
    "    ytrue = []\n",
    "    ypreds = []\n",
    "    with torch.no_grad():\n",
    "        for x, x_adj, y in data_iter:\n",
    "            yhat = model(x, x_adj)\n",
    "            yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "            ytrue.extend(list(y.numpy()))\n",
    "            ypreds.extend(yhat)\n",
    "\n",
    "    return (accuracy_score(ytrue, ypreds), \n",
    "            confusion_matrix(ytrue, ypreds), \n",
    "            precision_score(ytrue, ypreds), \n",
    "            recall_score(ytrue, ypreds),\n",
    "            f1_score(ytrue, ypreds))\n",
    "\n",
    "def evaluate_model(model, loss_func, data_iter):\n",
    "    model.eval()\n",
    "    loss_sum, n = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, x_adj, y in data_iter:\n",
    "            y_pred = model(x, x_adj)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            loss = loss_func(y_pred,y)\n",
    "            loss_sum += loss.item()\n",
    "            n += 1\n",
    "        return loss_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0828b0c4-ea8d-4fd1-b64e-fa2f94d91bf7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model....\n",
      "started training\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [06:20<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4537571369740315 ,Train Accuracy:  0.8041920903954802 ,F1:  0.7702364063059359 ,Precision:  0.9318276603253024 ,Recall:  0.6564067796610169\n",
      "Val loss: 0.5159348890636907 , Val Accuracy:  0.7381016949152542 ,F1:  0.6805061616078075 ,Precision:  0.8723494486853266 ,Recall:  0.5578305084745763\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [05:57<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3522290437336946 ,Train Accuracy:  0.8464632768361582 ,F1:  0.8281696552770681 ,Precision:  0.9401917997013897 ,Recall:  0.74\n",
      "Val loss: 0.5635575216053884 , Val Accuracy:  0.7513220338983051 ,F1:  0.7108851580357847 ,Precision:  0.8489269578313253 ,Recall:  0.611457627118644\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [05:55<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.30415976473878575 ,Train Accuracy:  0.8739096045197741 ,F1:  0.8781249658697481 ,Precision:  0.8497178246073852 ,Recall:  0.908497175141243\n",
      "Val loss: 0.6039410845025793 , Val Accuracy:  0.7412203389830508 ,F1:  0.749573546778638 ,Precision:  0.7261344858268718 ,Recall:  0.7745762711864407\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:52<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.2665473829976396 ,Train Accuracy:  0.8761920903954802 ,F1:  0.862699397265767 ,Precision:  0.968216465558462 ,Recall:  0.7779209039548023\n",
      "Val loss: 0.619712154973637 , Val Accuracy:  0.7494237288135593 ,F1:  0.7085173501577287 ,Precision:  0.8467483506126295 ,Recall:  0.6090847457627119\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█                                         | 17/692 [00:07<04:57,  2.27it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [275]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#print(y_pred.shape, y.shape)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(y_pred, y)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/_tensor.py:482\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    474\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    475\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 482\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/autograd/__init__.py:191\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 191\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "# Model and optimizer\n",
    "gcn = GCN(nfeat=features.shape[1], nhid=4, nclass=2, dropout=0.5)\n",
    "gcn.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(gcn.parameters(), lr=1e-3)\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "print(\"started training\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, adj_x ,y) in enumerate(tqdm(data_iter)):\n",
    "        y_pred = gcn(x, adj_x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        #print(y_pred.shape, y.shape)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(gcn, loss_func, val_data_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(gcn, data_iter)[0], \",F1: \", \n",
    "        cal_accuracy(gcn, data_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(gcn, data_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(gcn, data_iter)[3])\n",
    "    \n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(gcn, val_data_iter)[0], \",F1: \", \n",
    "        cal_accuracy(gcn, val_data_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(gcn, val_data_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(gcn, val_data_iter)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8da4cb85-1da6-49da-8dd0-b54d5a91b842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8369565217391305\n",
      "Test Confusion:  [[231   0]\n",
      " [ 45   0]]\n",
      "Test F1:  0.0\n",
      "Test Recall:  0.0\n",
      "Test Precision:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedr/opt/anaconda3/envs/xai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, test_adj, y in test_data_iter:\n",
    "        yhat = gcn(x, test_adj)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "        \n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d6e27-bd23-4f5b-8874-519b210aff24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f380e-79d1-4356-a682-3c126843d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d71219-a78d-46f1-b999-76b22750a62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34417788-c04a-4a45-bee1-df616d0f9258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d79d9-8f6b-4c54-9956-fbfd4bb04e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af04f6c-78db-45f8-8b04-c1c000735d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
