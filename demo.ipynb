{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26f46c8-2a8a-4a73-9308-d435502bd326",
   "metadata": {},
   "source": [
    "# ChronoNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4666faf2-30e3-4ce8-a625-f3c98327fe5a",
   "metadata": {},
   "source": [
    "Here we train the model and record the train and validation accuracy. We used subset of the temple dataset for faster training. we used 500 subjects only for training and validation of the model. The recorded metrics are accuracy, binary cross entropy loss, F1 score, Precision and Recall.\n",
    "\n",
    "- Train Data: 500 subjects\n",
    "\n",
    "- Test Data: 276 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96d47023-733f-4137-a16d-a08406cefc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedr/opt/anaconda3/envs/xai/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data....\n",
      "Scaling Data....\n",
      "Data Loader....\n",
      "Training Model....\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:34<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6135080639337529 ,Train Accuracy:  0.7996045197740113 ,F1:  0.7803633571525878 ,Precision:  0.8632490341671918 ,Recall:  0.712\n",
      "Val loss: 0.6022120368429077 , Val Accuracy:  0.7723050847457628 ,F1:  0.741564387672656 ,Precision:  0.8573080686771639 ,Recall:  0.6533559322033898\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:21<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5856635680777489 ,Train Accuracy:  0.8226892655367232 ,F1:  0.7964404317144043 ,Precision:  0.934831597539436 ,Recall:  0.6937401129943502\n",
      "Val loss: 0.5953799966093781 , Val Accuracy:  0.7829830508474577 ,F1:  0.7506232471174821 ,Precision:  0.8821644387474822 ,Recall:  0.6532203389830509\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:45<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5753913293511881 ,Train Accuracy:  0.8453446327683616 ,F1:  0.8308555469049296 ,Precision:  0.9167416618942431 ,Recall:  0.7596836158192091\n",
      "Val loss: 0.5960082494335257 , Val Accuracy:  0.792 ,F1:  0.7715221924337206 ,Precision:  0.8557739963654386 ,Recall:  0.7023728813559322\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:30<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.570163000353499 ,Train Accuracy:  0.8605762711864406 ,F1:  0.8510484192228297 ,Precision:  0.9134727513021845 ,Recall:  0.7966101694915254\n",
      "Val loss: 0.595359214972624 , Val Accuracy:  0.7965084745762712 ,F1:  0.7804717498628635 ,Precision:  0.8472409686383485 ,Recall:  0.723457627118644\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [04:15<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.565777277498576 ,Train Accuracy:  0.8552542372881355 ,F1:  0.8381267691063485 ,Precision:  0.9506105601100728 ,Recall:  0.7494463276836159\n",
      "Val loss: 0.5963385198023412 , Val Accuracy:  0.7821016949152543 ,F1:  0.7513346228239846 ,Precision:  0.8748648648648648 ,Recall:  0.6583728813559322\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "from load_data import read_data_arrays, data_file_names, standardize_data, data_loader\n",
    "from models import ChronoNet\n",
    "from utils import cal_accuracy, evaluate_model \n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "#device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "print(\"Reading Data....\")\n",
    "sample_size = 500\n",
    "data_files = data_file_names(sample_size)\n",
    "(train_features, val_features, test_features,\n",
    " train_labels, val_labels, test_labels, test_lengths) = read_data_arrays(\n",
    "    data_files)\n",
    "    \n",
    "print(\"Scaling Data....\")\n",
    "train_features, val_features, test_features = standardize_data(\n",
    "    train_features, val_features, test_features)\n",
    "    \n",
    "print(\"Data Loader....\")\n",
    "train_iter = data_loader(train_features, train_labels, DEVICE, BATCH_SIZE)\n",
    "val_iter = data_loader(val_features, val_labels, DEVICE, BATCH_SIZE)\n",
    "test_iter = data_loader(test_features, test_labels, DEVICE, BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "model=ChronoNet(n_chans)\n",
    "model.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, val_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(model, train_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, train_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, train_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, train_iter)[3])\n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(model, val_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, val_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, val_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, val_iter)[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4ec1d-fbd4-4d0f-9173-e2ae3534691d",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7220e28-acda-411d-9eec-2c5f22572cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8188405797101449\n",
      "Test Confusion:  [[141   9]\n",
      " [ 41  85]]\n",
      "Test F1:  0.7727272727272727\n",
      "Test Recall:  0.6746031746031746\n",
      "Test Precision:  0.9042553191489362\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_iter:\n",
    "        yhat = model(x)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "        \n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619dde7-c736-40dc-a86e-b8dad07c2809",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254afb0b-0902-4330-bc50-14afd53623a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model....\n",
      "started training\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [08:51<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.661770528279288 ,Train Accuracy:  0.7018870056497175 ,F1:  0.624489389259739 ,Precision:  0.843477257872275 ,Recall:  0.49577401129943505\n",
      "Val loss: 0.67322963032068 , Val Accuracy:  0.5675593220338983 ,F1:  0.2789803877239586 ,Precision:  0.8386000679578661 ,Recall:  0.16732203389830508\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [36:10<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6248360861071273 ,Train Accuracy:  0.7378757062146892 ,F1:  0.6679738936279842 ,Precision:  0.9108829729096729 ,Recall:  0.5273446327683616\n",
      "Val loss: 0.6709002801016265 , Val Accuracy:  0.5743050847457627 ,F1:  0.2901074053137365 ,Precision:  0.8727891156462585 ,Recall:  0.17396610169491525\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [13:54<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6036012842820558 ,Train Accuracy:  0.7931073446327683 ,F1:  0.7555798803929944 ,Precision:  0.9229991520448764 ,Recall:  0.6395706214689265\n",
      "Val loss: 0.6608413919514301 , Val Accuracy:  0.602 ,F1:  0.3752461022721226 ,Precision:  0.8721246599060104 ,Recall:  0.2390508474576271\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [13:37<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5900325086075446 ,Train Accuracy:  0.8101694915254237 ,F1:  0.777824798984342 ,Precision:  0.937575718931327 ,Recall:  0.6645875706214689\n",
      "Val loss: 0.6607672583823111 , Val Accuracy:  0.604 ,F1:  0.37907940895078135 ,Precision:  0.8774606299212598 ,Recall:  0.2417627118644068\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 692/692 [17:01<00:00,  1.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5812325871231928 ,Train Accuracy:  0.833683615819209 ,F1:  0.8115485564304462 ,Precision:  0.9361394181066313 ,Recall:  0.716225988700565\n",
      "Val loss: 0.6539293941329507 , Val Accuracy:  0.6249830508474576 ,F1:  0.44049967126890205 ,Precision:  0.8670117459685447 ,Recall:  0.2952542372881356\n"
     ]
    }
   ],
   "source": [
    "from models import LSTM\n",
    "\n",
    "learning_rate = 5e-3\n",
    "\n",
    "model = LSTM(input_size=500, num_channels=19, hidden_units=128)\n",
    "\n",
    "print(\"Training Model....\")\n",
    "n_chans = 19\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "model.to(DEVICE)\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "print(\"started training\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(\"Epoch\", epoch) \n",
    "    loss_sum, n = 0.0, 0\n",
    "    model.train()\n",
    "    for t, (x, y) in enumerate(tqdm(train_iter)):\n",
    "        y_pred = model(x)\n",
    "        y_pred = y_pred.squeeze()\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    val_loss = evaluate_model(model, loss_func, test_iter)\n",
    "    print(\"Train loss:\", loss_sum / (t+1), \",Train Accuracy: \", \n",
    "        cal_accuracy(model, train_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, train_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, train_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, train_iter)[3])\n",
    "    print(\"Val loss:\", val_loss, \", Val Accuracy: \", \n",
    "        cal_accuracy(model, val_iter)[0], \",F1: \", \n",
    "        cal_accuracy(model, val_iter)[4], \",Precision: \", \n",
    "        cal_accuracy(model, val_iter)[2], \",Recall: \", \n",
    "        cal_accuracy(model, val_iter)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82189487-7315-4a8c-b73f-f60d7c24c742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6485507246376812\n",
      "Test Confusion:  [[149   1]\n",
      " [ 96  30]]\n",
      "Test F1:  0.38216560509554137\n",
      "Test Recall:  0.23809523809523808\n",
      "Test Precision:  0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "ytrue = []\n",
    "ypreds = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_iter:\n",
    "        yhat = model(x)\n",
    "        yhat = [0 if i<0.5 else 1 for i in yhat]\n",
    "        ytrue.extend(list(y.numpy()))\n",
    "        ypreds.extend(yhat)\n",
    "\n",
    "y_final = []\n",
    "yhat_final = []\n",
    "for i in range(0, len(ytrue), 118): \n",
    "    major_y_final = Counter(ytrue[i: i+118]).most_common(1)[0][0]\n",
    "    major_yhat_final = Counter(ypreds[i: i+118]).most_common(1)[0][0]\n",
    "    y_final.append(major_y_final)\n",
    "    yhat_final.append(major_yhat_final)\n",
    "    \n",
    "print(\"Test Accuracy: \", accuracy_score(y_final, yhat_final))\n",
    "print(\"Test Confusion: \",confusion_matrix(y_final, yhat_final))\n",
    "print(\"Test F1: \", f1_score(y_final, yhat_final))\n",
    "print(\"Test Recall: \", recall_score(y_final, yhat_final))\n",
    "print(\"Test Precision: \", precision_score(y_final, yhat_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ba1b7-5469-4d4d-b942-2e97c64fde87",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0f36fc-045e-4a3e-9834-aa6a1836ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.LSTM = LSTM(input_size=500, num_channels=19, hidden_units=32)\n",
    "        self.ChronoNet = ChronoNet(19)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        #print(input.shape, self.weight.shape)\n",
    "        #support = torch.matmul(input, self.weight)\n",
    "        support = self.ChronoNet(input)\n",
    "        print(adj.shape, support.shape)\n",
    "        output = torch.matmul(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "    \n",
    "        \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from pygcn.layers import GraphConvolution\n",
    "\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "\n",
    "def load_data(path=\"../cora/\", dataset=\"cora\"):\n",
    "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
    "    print('Loading {} dataset...'.format(dataset))\n",
    "\n",
    "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
    "                                        dtype=np.dtype(str))\n",
    "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "    labels = encode_onehot(idx_features_labels[:, -1])\n",
    "\n",
    "    # build graph\n",
    "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "    idx_map = {j: i for i, j in enumerate(idx)}\n",
    "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                    dtype=np.int32)\n",
    "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                     dtype=np.int32).reshape(edges_unordered.shape)\n",
    "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                        shape=(labels.shape[0], labels.shape[0]),\n",
    "                        dtype=np.float32)\n",
    "\n",
    "    # build symmetric adjacency matrix\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    features = normalize(features)\n",
    "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "\n",
    "    idx_train = range(140)\n",
    "    idx_val = range(200, 500)\n",
    "    idx_test = range(500, 1500)\n",
    "\n",
    "    features = torch.FloatTensor(np.array(features.todense()))\n",
    "    labels = torch.LongTensor(np.where(labels)[1])\n",
    "    adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "\n",
    "    idx_train = torch.LongTensor(idx_train)\n",
    "    idx_val = torch.LongTensor(idx_val)\n",
    "    idx_test = torch.LongTensor(idx_test)\n",
    "\n",
    "    return adj, features, labels, idx_train, idx_val, idx_test\n",
    "\n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Block(nn.Module):\n",
    "  def __init__(self,inplace):\n",
    "    super().__init__()\n",
    "    self.conv1=nn.Conv1d(in_channels=inplace,out_channels=inplace,kernel_size=2,stride=2,padding=0)\n",
    "    self.conv2=nn.Conv1d(in_channels=inplace,out_channels=inplace,kernel_size=4,stride=2,padding=1)\n",
    "    self.conv3=nn.Conv1d(in_channels=inplace,out_channels=inplace,kernel_size=8,stride=2,padding=3)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x1=self.relu(self.conv1(x))\n",
    "    x2=self.relu(self.conv2(x))\n",
    "    x3=self.relu(self.conv3(x))\n",
    "    x=torch.cat([x1,x3,x3],dim=1)\n",
    "    return x\n",
    "\n",
    "class ChronoNet(nn.Module):\n",
    "  def __init__(self,channel):\n",
    "    super().__init__()\n",
    "    self.block1=Block(channel)\n",
    "    self.block2=Block(57)\n",
    "    self.block3=Block(171)\n",
    "    self.gru1=nn.LSTM(input_size=513,hidden_size=32,batch_first=True)\n",
    "    self.gru2=nn.LSTM(input_size=32,hidden_size=32,batch_first=True)\n",
    "    self.gru3=nn.LSTM(input_size=64,hidden_size=32,batch_first=True)\n",
    "    self.gru4=nn.LSTM(input_size=96,hidden_size=32,batch_first=True)\n",
    "    self.gru_linear=nn.Linear(62,19)\n",
    "    self.flatten=nn.Flatten()\n",
    "    #self.fc1=nn.Linear(32,1)\n",
    "    self.relu=nn.ReLU()\n",
    "\n",
    "  def forward(self,x):\n",
    "    x = x.squeeze()\n",
    "    x=self.block1(x)\n",
    "    \n",
    "    x=self.block2(x)\n",
    "\n",
    "    x=self.block3(x)\n",
    "\n",
    "    x=x.permute(0,2,1)\n",
    "    gru_out1,_=self.gru1(x)\n",
    "    gru_out2,_=self.gru2(gru_out1)\n",
    "    gru_out=torch.cat([gru_out1, gru_out2],dim=2)\n",
    "    gru_out3,_=self.gru3(gru_out)\n",
    "    gru_out=torch.cat([gru_out1, gru_out2, gru_out3],dim=2)\n",
    "    print(gru_out.shape)\n",
    "    linear_out=self.relu(self.gru_linear(gru_out))\n",
    "    gru_out4,_=self.gru4(linear_out.permute(0,2,1))\n",
    "    #gru_out4 = gru_out4.permute(0,2,1)\n",
    "    return gru_out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d7fa06e-4769-45a6-be07-9c44c845a5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 19, 32])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adj.shape, features.shape\n",
    "features = torch.rand(3, 19, 32)\n",
    "adj = torch.rand(3, 19, 19)\n",
    "aa = torch.matmul(adj, features)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1eafc5-74d7-4508-b460-422a5f9b4a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 96])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (12x96 and 62x19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN(nfeat\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      7\u001b[0m             nhid\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      8\u001b[0m             nclass\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m             dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m output\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj):\n\u001b[0;32m---> 65\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     66\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     67\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgc2(x, adj)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mGraphConvolution.forward\u001b[0;34m(self, input, adj)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, adj):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#print(input.shape, self.weight.shape)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#support = torch.matmul(input, self.weight)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     support \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChronoNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(adj\u001b[38;5;241m.\u001b[39mshape, support\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     39\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(adj, support)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mChronoNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m gru_out\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat([gru_out1, gru_out2, gru_out3],dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mprint\u001b[39m(gru_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 203\u001b[0m linear_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgru_out\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    204\u001b[0m gru_out4,_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru4(linear_out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m#gru_out4 = gru_out4.permute(0,2,1)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/xai/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (12x96 and 62x19)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Model and optimizer\n",
    "model = GCN(nfeat=features.shape[2],\n",
    "            nhid=features.shape[2],\n",
    "            nclass=2,\n",
    "            dropout=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "output = model(features, adj)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0828b0c4-ea8d-4fd1-b64e-fa2f94d91bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
